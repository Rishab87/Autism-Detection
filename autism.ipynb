{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A1  A2  A3  A4  Age_Mons  Qchat-10-Score Family_mem_with_ASD  \\\n",
      "0   0   0   0   0        28               3                  no   \n",
      "1   1   1   0   0        36               4                  no   \n",
      "2   1   0   0   0        36               4                  no   \n",
      "3   1   1   1   1        24              10                  no   \n",
      "4   1   1   0   1        20               9                 yes   \n",
      "\n",
      "  Class/ASD Traits   \n",
      "0                No  \n",
      "1               Yes  \n",
      "2               Yes  \n",
      "3               Yes  \n",
      "4               Yes  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./autism/Toddler Autism dataset July 2018.csv')\n",
    "\n",
    "selected_columns = ['A1', 'A2', 'A3', 'A4', 'Age_Mons', 'Qchat-10-Score' , 'Family_mem_with_ASD', 'Class/ASD Traits ']\n",
    "df = data[selected_columns]\n",
    "\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931471805599453\n",
      "Epoch 100, Loss: 0.2796471806009027\n",
      "Epoch 200, Loss: 0.23079770533613805\n",
      "Epoch 300, Loss: 0.20965841168715504\n",
      "Epoch 400, Loss: 0.19739856255147875\n",
      "Epoch 500, Loss: 0.18921122283313702\n",
      "Epoch 600, Loss: 0.18326014775904606\n",
      "Epoch 700, Loss: 0.17867956158062454\n",
      "Epoch 800, Loss: 0.17500378313596976\n",
      "Epoch 900, Loss: 0.1719585089682983\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "data['Family_mem_with_ASD'] = data['Family_mem_with_ASD'].map({'yes': 1, 'no': 0})\n",
    "data['Class/ASD Traits '] = data['Class/ASD Traits '].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Normalize numerical columns\n",
    "numerical_cols = ['Age_Mons', 'Qchat-10-Score']\n",
    "data[numerical_cols] = data[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "data[numerical_cols] = (data[numerical_cols] - data[numerical_cols].mean()) / data[numerical_cols].std()\n",
    "\n",
    "# Select features and labels\n",
    "X = df[selected_columns[:-1]].apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "y = df[selected_columns[-1]].map({'Yes': 1, 'No': 0}).values.reshape(-1, 1)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_loss(y, y_hat):\n",
    "    m = len(y)\n",
    "    return - (1/m) * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "def logistic_regression(X, y, learning_rate=0.01, epochs=1000, regularization=0.01):\n",
    "    m , n = X.shape\n",
    "    W = np.zeros((n, 1))  \n",
    "    b = 0                 \n",
    "    for epoch in range(epochs):\n",
    "        z = np.dot(X, W) + b\n",
    "        y_hat = sigmoid(z)\n",
    "         # Compute loss with L2 regularization\n",
    "        loss = log_loss(y, y_hat) + (regularization / (2 * m)) * np.sum(W**2)\n",
    "\n",
    "        dW = (1/m) * np.dot(X.T, (y_hat - y)) + (regularization / m) * W\n",
    "        db = (1/m) * np.sum(y_hat - y)\n",
    "        W = W - learning_rate * dW\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "    return W, b\n",
    "\n",
    "# Train logistic regression model\n",
    "W, b = logistic_regression(X, y)\n",
    "\n",
    "\n",
    "# Predict new data\n",
    "def predict(X, W, b):\n",
    "    z = np.dot(X, W) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return (y_hat >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for new data: Autistic\n"
     ]
    }
   ],
   "source": [
    "X_new = np.array([[1, 1, 0, 1, 24, 7, 0]])  # New sample\n",
    "X_new[:, 4:6] = (X_new[:, 4:6] - data[numerical_cols].mean().values) / data[numerical_cols].std().values  # Normalize\n",
    "prediction = predict(X_new, W, b)\n",
    "print(\"Prediction for new data:\", \"Autistic\" if prediction[0] == 1 else \"Not Autistic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
